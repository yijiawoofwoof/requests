{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yijiawoofwoof/requests/blob/master/linreg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1o43hJ7LQz5"
      },
      "source": [
        "# Introduction to Linear Regression\n",
        "\n",
        "#### Adapted from Data and Decisions regression handouts for Python, by Mohsen Bayati\n",
        "\n",
        "<hr>\n",
        "\n",
        "First importing some necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qR75BNRBLTau"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn; seaborn.set()\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqvV6EflKeqk"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## 1. Simple regression as describing a pattern in the data\n",
        "\n",
        "\n",
        "We imagine that we have a scatter of $n$ points $(X_i, Y_i)$ for $i=1,2, \\ldots$ and, in an attempt to describe how the points covary or\n",
        "correlate, we try to find the line\n",
        "$$Y=a+bX$$\n",
        "that \"most closely\"\n",
        "conforms to the scatter of points.  Regression finds the slope and\n",
        "intercept that make the \"sum of squared deviations\" around the\n",
        "regression line,\n",
        "$$\n",
        "\\sum_{\\text{data points}} (\\text{actual} - \\text{predicted})^2\n",
        "$$\n",
        "as small as possible.  In mathematical terms, regression finds the pair\n",
        "of constants $a$ and $b$ that minimize the sum\n",
        "$$\n",
        "\\sum_{i=1}^n\n",
        "\\left[Y_i-(a+bX_i)\\right]^2\\,.\n",
        "$$\n",
        "A measure of how well this line does in fitting the data is called the\n",
        "*coefficient of determination*, or $R^2$ (read R-squared) for\n",
        "short.  $R^2$ is interpreted as the proportion of variation in the $Y$\n",
        "values that is explained by the regression line.  If all the points\n",
        "lie along a single line, $R^2$ will be one (unless the $Y$ values are\n",
        "constant -- in which case $R^2$ is undefined).  If the best line we\n",
        "can find is perfectly flat, so none of the variation in $Y$ is\n",
        "explained by the line, then $R^2$ is zero.\n",
        "\n",
        "## 2. Regression in Python\n",
        "\n",
        "We can build a regression model in Python using the `ols` command from `statsmodels.formula.api` package. First, we can load a data set containing\n",
        "52 weeks of demand and price information for a major coffee producer in Cypress. This can be done by the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "248xEIWvLHv8"
      },
      "outputs": [],
      "source": [
        "coffee = pd.read_csv(\"https://raw.githubusercontent.com/mohsenbayati/oit367/main/data/Cypress.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY-Mv1iTLzGl"
      },
      "source": [
        "and now we inspect the top rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9vKJrdV2MDrk",
        "outputId": "034a1e23-fb3b-4ac0-9147-0e42d4222850"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Week</th>\n",
              "      <th>Demand</th>\n",
              "      <th>PricePerKg</th>\n",
              "      <th>Summer</th>\n",
              "      <th>Winter</th>\n",
              "      <th>CompetitorsPrice</th>\n",
              "      <th>Advertising</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>395.79</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>570.90</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>490.97</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>489.21</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>469.25</td>\n",
              "      <td>9.9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Week  Demand  PricePerKg  Summer  Winter  CompetitorsPrice  Advertising\n",
              "0     1  395.79         9.0       0       0               9.0          500\n",
              "1     2  570.90         9.0       0       0               9.0          500\n",
              "2     3  490.97         9.0       0       0               9.0          500\n",
              "3     4  489.21         9.0       1       0               9.0            0\n",
              "4     5  469.25         9.9       1       0               9.0            0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "coffee.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMXSx9ugMLBB"
      },
      "source": [
        "Next we will use the following command to regress `Demand` on `PricePerKg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSCxhCJtMa1D"
      },
      "outputs": [],
      "source": [
        "reg_setup = smf.ols(formula = 'Demand~PricePerKg', data = coffee)\n",
        "model = reg_setup.fit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj44jv85MuFJ"
      },
      "source": [
        "In order to see the details of the regression model we can use the command `model.summary()` and the result is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjOG9hF_Mzmo",
        "outputId": "7773e807-50c7-4862-e054-2f9a5a8388ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                 Demand   R-squared:                       0.038\n",
            "Model:                            OLS   Adj. R-squared:                  0.019\n",
            "Method:                 Least Squares   F-statistic:                     1.992\n",
            "Date:                Wed, 07 Jan 2026   Prob (F-statistic):              0.164\n",
            "Time:                        11:37:17   Log-Likelihood:                -286.27\n",
            "No. Observations:                  52   AIC:                             576.5\n",
            "Df Residuals:                      50   BIC:                             580.4\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept    636.5048    122.034      5.216      0.000     391.392     881.618\n",
            "PricePerKg   -19.0448     13.492     -1.412      0.164     -46.145       8.056\n",
            "==============================================================================\n",
            "Omnibus:                        0.538   Durbin-Watson:                   1.931\n",
            "Prob(Omnibus):                  0.764   Jarque-Bera (JB):                0.418\n",
            "Skew:                          -0.214   Prob(JB):                        0.812\n",
            "Kurtosis:                       2.899   Cond. No.                         133.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOqLWGKrNJaq"
      },
      "source": [
        "In class we will discuss the results in more details.\n",
        "\n",
        "\n",
        "**Remark (linear regression by sklearn package):** There is an alternative package to perform linear regression in python, as part of the general machine learning package. `sklearn`. Specifically, the python function `sklearn.linear_model.LinearRegression()`. We will showcase the use of this package in the future. If one is interested in their differences, a high-level comparision is as follows: `smf.ols()` brings similar functionalitys as the R version of linear regression `lm`. However, `sklearn.linear_model.LinearRegression()` is part of a general family of machine learning packages in python that all have very similar syntax. Therefore, if one is aiming to use linear regression for prediction purposes, with code sytanx in the unified format of `sklearn`, then\n",
        "`sklearn.linear_model.LinearRegression()` should be used. Otherwise, `smf.ols()` is better, given the detailed output as shown above.\n",
        "\n",
        "## 3. Statistical Inference in a Simple Regression\n",
        "\n",
        "### 3.1. Setting\n",
        "\n",
        "We have observations of two variables, $Y$, the dependent variable,\n",
        "and $X$,the independent variable.  Specifically, we have $n$\n",
        "observations, and we write $(Y_i, X_i)$ for the $i$th pair of numbers.\n",
        "\n",
        "We imagine that\n",
        "$$Y_i=\\alpha+\\beta X_i+\\varepsilon_i$$\n",
        "where $\\alpha$\n",
        "and $\\beta$ are constants, and $\\varepsilon$ is an\n",
        "observation-specific \"chance error\" term -- which we usually assume\n",
        "is Normally distributed with mean zero and some (unknown) variance\n",
        "$\\sigma^2$.\n",
        "\n",
        "**Remark**: The Normality of the chance error term is not\n",
        "really essential unless we are interested in confidence intervals\n",
        "around forecasts; for all other purposes, as long as the sample is\n",
        "large enough, the central limit theorem says that most of what follows is approximately true.\n",
        "\n",
        "Our problem is that we don't know $\\alpha$, $\\beta$ or $\\sigma^{2}$. So we will use the data sample to estimate and make inferences about these variables.\n",
        "\n",
        "\n",
        "### 3.2 Estimates from the regression\n",
        "\n",
        "The estimates we compute for $\\alpha$ and $\\beta$ are the same\n",
        "regression coefficients $\\hat\\alpha$ and $\\hat\\beta$ that minimize the sum of squared\n",
        "deviations in the sample.  It turns out that the formulae\n",
        "that give $\\hat\\alpha$ and $\\hat\\beta$ from the data are (very good) unbiased\n",
        "estimators of $\\alpha$ and $\\beta$: On average (meaning, averaging\n",
        "across results from sample to sample), the numbers we compute for $\\hat\\alpha$ and $\\hat\\beta$ are equal to the true (unknown) values $\\alpha$ and $\\beta$.\n",
        "In the output of Cypress coffee resgression (shown above) $\\hat\\alpha=636.50$\n",
        "and $\\hat\\beta = -19.04$. Next we calculate the Mean Squared Error (MSE) and the Root Mean Squared Error (RMSE).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAeiYfORkJcT",
        "outputId": "f7af6c5a-4dff-4db0-af55-6841e11fa260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE) is:  3541.5710616454285\n",
            "Root Mean Squared Error (RMSE) is:  59.51110032292655\n"
          ]
        }
      ],
      "source": [
        "MSE = (model.resid**2).sum()/(len(model.resid))\n",
        "RMSE = np.sqrt(MSE)\n",
        "print('Mean Squared Error (MSE) is: ', MSE)\n",
        "print('Root Mean Squared Error (RMSE) is: ', RMSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYIwo60tkJcU"
      },
      "source": [
        "In other words, MSE is the mean square error of the regression, which is the sum of the squares of the deviations, divided by the number of points in the sample. Furthermore, RMSE is the square root of this value, which simply is the *average prediction error* of the regression.\n",
        "\n",
        "Note that as we observe later, usually RMSE on the data used for building the regression model (training data) is less important than RMSE calculated on a separate data set (validation data). Since, it is the latter RMSE that shows whether the regression model is generalizable. We will discuss this in class. Be sure you know where to find $\\hat\\alpha$, $\\hat\\beta$, and RMSE in the code above, and how to interpret them.\n",
        "\n",
        "**Remark:** In some software like Excel, the mean square error is computed by dividing by $n-2$ (or generally degrees of freedom of residuals) rather than $n$, a convention statisticians prefer to obtain a property called *unbiasedness* of the variance estimate.  In applications with any reasonable sample size, however, the use of $n$ versus $n-2$ makes little difference. If you are interested to find this adjusted MSE value you can simply use ``mse_resid`` method within statsmodels. As a sanity check, we have also calculated this value by simply dividing the total error by $n-2$ rather than $n$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmDVkv8nkJcU",
        "outputId": "f0e215a2-c838-4f07-fb58-567194708e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adjusted MSE is:  3683.233904111247\n",
            "Adjusted MSE (second way) is:  3683.2339041112455\n"
          ]
        }
      ],
      "source": [
        "adjusted_MSE = model.mse_resid\n",
        "print('Adjusted MSE is: ', adjusted_MSE)\n",
        "adjusted_MSE_2 = (model.resid**2).sum()/(len(model.resid)-2)\n",
        "print('Adjusted MSE (second way) is: ', adjusted_MSE_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6mUuOEAkJcW"
      },
      "source": [
        "As you observe, the difference is pretty small. So, it is fine to use any of these formulas to estiamte MSE or its root, i.e., RMSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYAOQ57gk61_"
      },
      "source": [
        "\n",
        "\n",
        "### 3.3 Standard errors of $\\hat\\alpha$ and $\\hat\\beta$\n",
        "\n",
        "Because our sample is random, the estimates $\\hat\\alpha$ and $\\hat\\beta$ of $\\alpha$ and\n",
        "$\\beta$ that we compute in a regression are random.  Sometimes they will\n",
        "be bigger than the constants they are meant to estimate, and sometimes\n",
        "less.\n",
        "\n",
        "Of course, the expected value (mean) of $\\hat\\alpha$ is $\\alpha$, and that of $\\hat\\beta$\n",
        "is $\\beta$; this is what it means that $\\hat\\alpha$ and $\\hat\\beta$ are unbiased\n",
        "estimates of $\\alpha$ and $\\beta$.\n",
        "\n",
        "But there will be some random variation in these estimates, and just\n",
        "as we discussed the standard deviation of the estimator $\\bar{X}$, we\n",
        "discuss and use the standard deviations of $\\hat\\alpha$ and $\\hat\\beta$.  If we knew\n",
        "$\\sigma^2$ (and the particular values of $X$ that we have to work\n",
        "with), we could write out precise expressions for these standard\n",
        "deviations.  But since we don't know $\\sigma^2$, we work with $s^2$\n",
        "as an estimate, and compute  *standard errors* for $\\hat\\alpha$ and $\\hat\\beta$.\n",
        "(This is entirely analogous to our previous use of $s_X$ as an estimate of the standard deviation of $X$, and\n",
        "$$\n",
        "\\frac{\\mathrm{SD}(x)}{\\sqrt{n}}\n",
        "$$ as an estimate of the standard error\n",
        "of $\\bar{X}$, and\n",
        "$$\n",
        "\\sqrt{ \\frac{\\mathrm{SD}(x)^2}{n_X}+\\frac{\\mathrm{SD}(y)^2}{n_Y} }\n",
        "$$\n",
        "as an estimate of the standard\n",
        "error for the difference in averages $\\bar{X} -\\bar{Y}$.)\n",
        "\n",
        "There are formulae for the standard errors for $\\hat\\alpha$ and $\\hat\\beta$, but in the\n",
        "multiple regression case they require matrix algebra to obtain and are\n",
        "a bit beyond the scope of this course.  You needn't bother with the\n",
        "formulae themselves, however.  Instead, you should understand what\n",
        "they are (estimates of the standard deviations of the random estimates\n",
        "$\\hat\\alpha$ and $\\hat\\beta$ of $\\alpha$ and $\\beta$), where to find them in python\n",
        "output, and what can be done with them (for which read on). For example, in the case of Cypress coffee regression output, SE$(\\hat\\alpha)=122.03$ and SE$(\\hat\\beta)=13.49$.\n",
        "\n",
        "### 3.4 Confidence intervals around $\\hat\\alpha$ and $\\hat\\beta$\n",
        "\n",
        "The above values of standard errors for $\\hat\\alpha$ and $\\hat\\beta$can be used to compute confidence intervals around\n",
        "the estimates.  This is analogous to how we constructed\n",
        "95% confidence intervals for life expectancy in Lecture 1. If the basic model\n",
        "$$Y = \\alpha +\\beta X +\\text{chance error}$$\n",
        "is correct, then 95% of all intervals computed as $\\hat\\beta \\pm 2\\text{SE}(\\beta)$ will contain the true slope $\\beta$, and similarly with $\\hat\\alpha \\pm 2\\text{SE}(\\hat\\alpha)$ for $\\alpha$ (a more accurate way is to use 1.96 instead of 2, but the difference is usually negligible). As before, these confidence intervals are based\n",
        "on the 95% rule using a normal approximation to the distribution of\n",
        "the random variables $\\hat\\alpha$ and $\\hat\\beta$; in small samples, this can be\n",
        "questionable but as $n$ becomes large the central limit theorem\n",
        "usually justifies our probabilities.  You needn't be concerned about\n",
        "the details of constructing other types of confidence intervals.  Just\n",
        "understand what these things mean (and what they don't).\n",
        "\n",
        "\n",
        "### 3.5 Testing for values for $\\alpha$ and $\\beta$\n",
        "\n",
        "The standard errors for $\\hat\\alpha$ and $\\hat\\beta$ are also used to test hypotheses\n",
        "concerning $\\alpha$ and $\\beta$ such as\n",
        "*Is $\\alpha$ significantly different from zero?* and\n",
        "*Is $\\beta$ significantly greater than zero?*  The usual techniques apply: You find the relevant $t$-statistic under the null hypothesis, and see how far out in its distribution (under the null) the observed value of $\\hat\\alpha$ or $\\hat\\beta$ lies.\n",
        "\n",
        "\n",
        "If we want to test, say, whether $\\beta = 0$, the appropriate $t$-statistic to look at is\n",
        "$$\n",
        "\\frac{\\hat\\beta}{\\mathrm{SE}(\\hat\\beta)}\\,.\n",
        "$$\n",
        "Python does this calculation for us. If you for example look at the output of Cypress coffee regression, it shows $t$ value of $-1.412$. Now, as a sanity check, we can also calculate this manually\n",
        "$$\n",
        "t=\\frac{\\hat\\beta}{\\mathrm{SE}(\\hat\\beta)}=\\frac{-19.04}{13.49}=-1.411416\\,.\n",
        "$$\n",
        "\n",
        "We can, now use `t.cdf()` or `norm.cdf()` (accurate for $n\\geq 30$) from `scipy.stats` library or Normal tables to find the just-significant probability (the $p$-value), one-sided or two-sided, as we like.  Again, Python does this for you automatically, giving you (against a null hypotheses that $\\alpha = 0$ and $\\beta = 0$), the $p$-values for a two-sided test. In Cypress coffee regression these valus are $3.51\\times 10^{-6}$ and $0.164$ respectively.\n",
        "\n",
        "It is not unlikely that someday you will have occasion to test a null\n",
        "hypothesis of $\\beta$ = some value other than zero.  For example,\n",
        "suppose you have data on employee performance and amount of in-house\n",
        "training given to those employees.  You run a regression of Performance\n",
        "against Weeks of in-house training, and you find that more training\n",
        "seems to lead to better (higher) performance.  In fact, you find that\n",
        "the relationship is statistically significant; it is very unlikely that\n",
        "you would see the data you saw if in-house training had no impact on\n",
        "performance.\n",
        "\n",
        "That, however, isn't the point.  In-house training is expensive, and what\n",
        "you would like to know is whether in-house training sufficiently\n",
        "increases performance to be worth its cost.  In such a case, you would\n",
        "want to test a null hypothesis that $\\beta$ (the true return to an extra\n",
        "week of in-house training in terms of performance) is some level (that\n",
        "makes training economically worthwhile).\n",
        "\n",
        "In such cases, you will have to form your own hypothesis test; Python\n",
        "only tests against $\\alpha = 0$ and $\\beta = 0$.  But the test is\n",
        "simple.  Suppose, for Cypress coffee regression your null hypothesis is $\\beta = -10$. You form the\n",
        "$t$-statistic\n",
        "$$\n",
        "\\frac{\\hat\\beta-\\beta}{\\mathrm{SE}(\\hat\\beta)} = \\frac{-19.04 - (-10)}{13.49}=-0.7034841\n",
        "$$\n",
        "with a coffesponding $p$-value equal to\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1wuVnswlLal",
        "outputId": "bb2e66e7-e775-49a2-853c-d9fba43b8a7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p-value is equal to 0.48175411213101915\n"
          ]
        }
      ],
      "source": [
        "p_value = 2*norm.cdf(-0.7034841)\n",
        "print('p-value is equal to',p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_v_wO8tJkJcW"
      },
      "source": [
        "### 3.6 Forecasting/Prediction\n",
        "\n",
        "We can also use a regression to create a prediction, or forecast, for\n",
        "the value of $Y$ that will correspond to some new value of $X$.  If\n",
        "our data give regression estimates of $\\hat\\alpha$ and $\\hat\\beta$, our estimate of the\n",
        "value of $Y$ that will go with some new value of $X$ is (of course)\n",
        "$$\n",
        "\\hat{Y} = \\hat\\alpha+\\hat\\beta X\n",
        "$$\n",
        "or just the value along the regression line. In Python this can be done using the `predict` function. We will demonstrate this to you in class.\n",
        "\n",
        "This forecast is based on the regression estimates, and potentially\n",
        "subject to *forecast error*.  How much error is typical?  For\n",
        "this, we compute a standard error of the forecast, written as\n",
        "$\\text{SE}(\\hat{Y})$, and as discussed before, it is very close to RMSE (when $n$ is large).\n",
        "\n",
        "We use it to create a confidence interval around our point forecast.\n",
        "Note that the size of the standard error of the forecast,\n",
        "$\\text{SE}(\\hat{Y})$ is larger the further from $\\bar{X}$ is the value $X$\n",
        "that we are computing a forecast for.  This is because the further\n",
        "from $\\bar{X}$ is $X$, the greater will loom any errors we are making\n",
        "in our forecast.  This is an important point: the error likely to\n",
        "arise in a forecast at some value of $X$ increases (at an increasing\n",
        "rate) as $X$ moves away from its average value in the data.  Assuming\n",
        "the model is built sensibly, the $\\text{SE}(\\hat{Y})$ tells us\n",
        "by how much the typical forecast error increases.\n",
        "\n",
        "You should be clear on this point, and on how to use this formula to\n",
        "construct a confidence interval for a forecast (using, e.g., the usual\n",
        "2-$\\text{SE}$ rule) in a simple regression.\n",
        "\n",
        "## 4. Common pitfalls in the use of regression\n",
        "\n",
        "We will now discuss some of the most important pitfalls that arise in\n",
        "the use of regression.\n",
        "\n",
        "### 4.1 Causation vs. Correlation\n",
        "\n",
        "Simple regression tells you how the dependent and the independent\n",
        "variables are related.  Sometimes, however, knowing this relation will\n",
        "not be of much use to you and may even be misleading.  To see why,\n",
        "consider the following example.\n",
        "\n",
        "A manager of a car insurance company wishes to determine whether car\n",
        "anti-theft systems significantly reduce the probability of theft (if\n",
        "they do he may offer a discount to customers whose cars are equipped\n",
        "with such systems.) For this purpose he consults the company records.\n",
        "He randomly chooses a sample of 100 cars and collects information on\n",
        "whether they were stolen in the past five years and whether they had an\n",
        "anti-theft system.  He then defines the independent variable\n",
        "`AntiTheft` and the dependent variable `Theft` as follows.  For a\n",
        "given car `AntiTheft` is $1$ if the car had an anti-theft system and $0$\n",
        "if not and `Theft` is $1$ if the car was stolen in the past five years\n",
        "and $0$ if not.  Regressing `Theft` on `AntiTheft` he is very\n",
        "surprised to discover that the coefficient is positive, i.e.  if a car\n",
        "had an anti-theft system it was more likely to have been stolen! He\n",
        "wonders whether to recommend to his customers not to install anti-theft\n",
        "systems and in the case they do to charge them higher premia.\n",
        "\n",
        "So what has gone wrong? Regression told the manager correctly that cars\n",
        "with anti-theft systems are more likely to be stolen.  The reason for\n",
        "this fact is that higher quality cars are generally equipped with\n",
        "anti-theft systems but also appeal more to thieves.  The manager,\n",
        "however, is not so interested in knowing this fact.  He is rather\n",
        "interested in knowing by how much the installation of an anti-theft\n",
        "system on a car of a *given* quality will affect the probability of\n",
        "the car being stolen.\n",
        "\n",
        "The important conclusion that emerges is that when interpreting a\n",
        "regression result you should think whether this result answers the\n",
        "question you are interested in or whether it simply expresses some\n",
        "statistical correlation that is of no interest to you.  A regression is not capable of discerning cause and effect\n",
        "between two variables (if there are omitted variables); there is something you have to bring to the problem. In this case, regression has picked up a *spurious relationship*: both `AntiTheft` and `Theft` are being driven\n",
        "by another attribute that was left out of the regression, namely, the\n",
        "quality of the vehicle.\n",
        "\n",
        "How could one pick up on this problem, from a statistical perspective?\n",
        "One procedure would be to pick a subsample of cars of a given quality,\n",
        "then run a difference in means test between the percentage of cars\n",
        "with anti-theft systems that have been stolen and the percentage of\n",
        "cars without anti-theft systems that have been stolen.  Very shortly,\n",
        "we will see a second way to proceed when discussing multiple\n",
        "regression; we could introduce the \"omitted variable\" `Quality`\n",
        "and run a regression of `Theft` on both `AntiTheft` and `Quality`, using the whole sample.\n",
        "\n",
        "**Conclusion** If all potential confounding factors (omitted variables) are controlled for in the regression, then one can estimate the causal effect of a treatment.\n",
        "\n",
        "\n",
        "### 4.2  Nonlinear relationships in the data\n",
        "\n",
        "Regression supposes that the relationship between $X$ and $Y$ is linear\n",
        "and can give you some fairly misleading results if you estimate a\n",
        "relationship that in fact is nonlinear.  Therefore if you have a good\n",
        "reason to believe that a relationship is nonlinear (and there are many\n",
        "such relationships in the real world) you should not run a linear\n",
        "regression.  When discussing multiple regression we will see a way to\n",
        "estimate nonlinear relationships but for the moment let's go over an\n",
        "example that illustrates the problems of using linear regression to\n",
        "estimate a non-linear relationship.\n",
        "\n",
        "Suppose that you had to forecast weekly production costs of\n",
        "a manufacturing company, based on the output of its production line.\n",
        "It seems clear that there is\n",
        "relationship between output and cost of production, and so it would\n",
        "be natural to collect data on both for a\n",
        "number of weeks. Data of this ilk is shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6M58Lz-skD-J",
        "outputId": "1b84080f-4c10-49df-d8c0-9f964e728814",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ProductionCost</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1371.035673</td>\n",
              "      <td>71.280981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1389.734017</td>\n",
              "      <td>118.887075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1361.066250</td>\n",
              "      <td>70.835091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1429.442714</td>\n",
              "      <td>114.592596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1428.061247</td>\n",
              "      <td>134.430194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ProductionCost      Output\n",
              "0     1371.035673   71.280981\n",
              "1     1389.734017  118.887075\n",
              "2     1361.066250   70.835091\n",
              "3     1429.442714  114.592596\n",
              "4     1428.061247  134.430194"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prodData = pd.read_csv('https://raw.githubusercontent.com/mohsenbayati/oit367/main/data/WeeklyProd.csv')\n",
        "prodData.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nQf1RWWkLeq"
      },
      "source": [
        "The first column\n",
        "gives production costs in thousands of dollars, and the second column gives the\n",
        "output in 1000 units.\n",
        "\n",
        "It might seem natural to regress cost against output, to see\n",
        "what relationship emerges, and then to forecast cost on a given week\n",
        "given the relationship you find. The results of the regression using\n",
        "these data are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONj2MOOxkPog",
        "outputId": "03c513d7-d09d-4a94-c03e-e208a7eb7645"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:         ProductionCost   R-squared:                       0.620\n",
            "Model:                            OLS   Adj. R-squared:                  0.612\n",
            "Method:                 Least Squares   F-statistic:                     78.28\n",
            "Date:                Wed, 07 Jan 2026   Prob (F-statistic):           1.19e-11\n",
            "Time:                        11:37:17   Log-Likelihood:                -248.54\n",
            "No. Observations:                  50   AIC:                             501.1\n",
            "Df Residuals:                      48   BIC:                             504.9\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "Intercept   1294.5358     10.357    124.996      0.000    1273.712    1315.359\n",
            "Output         0.9784      0.111      8.848      0.000       0.756       1.201\n",
            "==============================================================================\n",
            "Omnibus:                       57.325   Durbin-Watson:                   2.198\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              423.893\n",
            "Skew:                          -2.859   Prob(JB):                     8.97e-93\n",
            "Kurtosis:                      16.068   Cond. No.                         193.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "reg_setup = smf.ols(formula = 'ProductionCost ~ Output', data = prodData)\n",
        "model= reg_setup.fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYydQy5BlAd4"
      },
      "source": [
        "We have an R-squared of 0.6199 -- the\n",
        "regression line explains around 62 percent of the variation in weekly\n",
        "production cost -- and a relationship that says that cost of increasing the output by 1000\n",
        "units is predicted to be around $\\$978$. In\n",
        "particular, if we forecast for a weekly output of $100,000$ units, we forecast\n",
        "the cost to be around $\\$1,392,377$, with a standard error around $\\$35,590$.\n",
        "\n",
        "But if we plot the production data, we might get a bit worried about\n",
        "the regression and the forecast. The scatter plot is shown below\n",
        ", and we note that for the few weeks with little output that we have seen, cost was quite low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "YOHrkm_glK0s",
        "outputId": "b5523245-4ee9-4021-e0e4-2c9540aad8b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Production cost ($000)')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(prodData['Output'],prodData['ProductionCost'])\n",
        "plt.xlabel('Output (000)')\n",
        "plt.ylabel('Production cost ($000)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqWyLrm1Dk2B"
      },
      "source": [
        "If we plot the\n",
        "residuals against the predictor variablewe see this\n",
        "more clearly - the regression produces residuals with downward bowl\n",
        "shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "bhFQ_C45DvMk",
        "outputId": "84207fbf-94d5-40df-bfdf-7737154fbba7",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'RegressionResiduals ($000)')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "prodData['RegressionResiduals'] = model.resid\n",
        "plt.scatter(prodData['Output'],prodData['RegressionResiduals'])\n",
        "plt.xlabel('Output (000)')\n",
        "plt.ylabel('RegressionResiduals ($000)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyL_yjR0LraE"
      },
      "source": [
        "Of course anyone familiar with the industry would not be misled by the\n",
        "regression.  It would be clear that cost vs. output has\n",
        "an inverted bowl shape -- low for low output, high for intermediate\n",
        "output and high (again) for high output.\n",
        "\n",
        "### 4.3 Out-of-population forecasting\n",
        "\n",
        "Let's say that you are a marketing manager for a car manufacturing\n",
        "company.  You are responsible for sales in two regions $A$ and $B$ and\n",
        "you want to make sales forecasts for the coming year.  You believe that\n",
        "the most important factor determining sales is income per person.\n",
        "Information on sales and income for the past 15 years is more readily\n",
        "available for region $A$ so you decide to estimate the relation between\n",
        "sales and income using this information and then to use current income\n",
        "for each region to forecast sales.\n",
        "\n",
        "The problem with this procedure is that you will get a misleading\n",
        "forecast for region $B$ (your forecast for region $A$ will be fine,\n",
        "although of course you should introduce more variables).  What I mean by\n",
        "a misleading forecast is that the confidence interval around your\n",
        "estimate for region $B$ sales will be too narrow making you feel much\n",
        "more certain about your estimate than you should be.  Maybe inhabitants\n",
        "of region $B$ depend more on public transportation than those of region\n",
        "$A$ and their demand is smaller and less sensitive to income.  This and\n",
        "probably other differences between regions $A$ and $B$ should make you\n",
        "put less weight on your confidence interval and feel more uncertain\n",
        "about your estimate.  You will get a good forecast only if regions $A$\n",
        "and $B$ are pretty similar, but you should otherwise be cautious in\n",
        "extrapolating regression results.\n",
        "\n",
        "We will see, how the use of *Training* vs *Validation* or *Test* data can help managing this challenge.\n",
        "\n",
        "## 5. Multiple Regression\n",
        "\n",
        "In a (multiple) linear regression, you have a dependent variable $Y$ and\n",
        "$k$ independent variables $X_1$ through $X_k$, and you hypothesize that\n",
        "the statistical relationship between them takes the form\n",
        "\n",
        "$$Y = \\beta_0 +\n",
        "\\beta_1 X_1 + \\ldots \\beta_k X_k + \\hbox{chance error}.$$\n",
        "\n",
        "Armed with a\n",
        "finite set of data (a set of observations on $(Y,X_1,\\ldots,X_k)$),\n",
        "regression produces for you estimates $a, b_1, b_2,\\ldots,b_k$ of the\n",
        "coefficients $\\beta_0,\\beta_1,\\ldots,\\beta_k$, as well as an estimate of the standard\n",
        "deviation of the error term.  It also produces standard errors of the\n",
        "various coefficient estimates so you can construct confidence\n",
        "intervals or test hypotheses concerning those coefficients, and it\n",
        "allows you to forecast the value of $Y$ that will correspond to a\n",
        "fresh vector of $X$s.\n",
        "\n",
        "This is all very nice, but there still seem to be some things that linear\n",
        "regression cannot do.  All variables have to be numbers and there seems\n",
        "to be no way to deal with categorical data (for instance data on a\n",
        "person's sex or occupation).  Moreover, the linearity of the model seems\n",
        "to preclude (i) a nonlinear relationship between an independent variable\n",
        "and the dependent variable and (ii) interaction effects, i.e.\n",
        "situations where the effect of an independent variable on the dependent\n",
        "variable depends on the value of another independent variable.\n",
        "\n",
        "Fortunately there are techniques for dealing with these situations in\n",
        "the context of linear regression.  These techniques are (i) dummy\n",
        "variables, (ii) nonlinear transformations of the independent variables\n",
        "and (iii) interaction terms.\n",
        "\n",
        "The main way to capture a nonlinear relationship between an\n",
        "independent variable $X$ and the dependent variable is to create\n",
        "nonlinear transformations of $X$ (like $X^2$ or $1/X$ or $\\log(X)$) and\n",
        "include them in the regression.  Nonlinear transformations of the\n",
        "independent variables allow us to extend the linear model to a more\n",
        "general model of the form\n",
        "\n",
        "$$Y=\\alpha+f_1(X_1)+\\ldots+f_k(X_k)$$\n",
        "\n",
        "for\n",
        "various classes of functions $f_1$ of $X_1$, $f_2$ of $X_2$ and so on.\n",
        "\n",
        "The first part of this note deals with the other two techniques: dummy\n",
        "variables and interaction terms.  As you will see, all three techniques\n",
        "help you generate a wealth of new variables.  When building a regression\n",
        "model and having a large number of independent variables however, there\n",
        "are some important mistakes that you should avoid doing.  The second\n",
        "part of the note points out these mistakes and gives you some guidelines\n",
        "for building regression models.\n",
        "\n",
        "### 5.1 Dummy variables or Binning\n",
        "\n",
        "When the population splits into two or more segments, and you believe\n",
        "that membership in one segment or another affects the \"intercept\" of\n",
        "the relationship between independent and dependent variables, you may\n",
        "use dummy variables.\n",
        "\n",
        "For example, suppose you are looking at real estate prices in two\n",
        "counties, San Mateo and Santa Clara.  More specifically, suppose you are\n",
        "trying to explain the price of single-family houses on the basis of\n",
        "square footage of the house and lot size.  (Serious regression analysis\n",
        "of single-family house prices would involve a lot more variables, but\n",
        "this will be enough to make the point.) In employing a linear\n",
        "regression, you are assuming that the relationship looks like\n",
        "\n",
        "$$\n",
        "\\text{Price of house} = \\beta_0 + \\beta_1 \\times\n",
        "\\text{feet}^2 + \\beta_2\\times\\text{lot size + chance error.}\n",
        "$$\n",
        "\n",
        "But it probably isn't that simple: because of\n",
        "differences in zoning ordinances, building codes, and county tax rates,\n",
        "you might think that the intercept $\\beta_0$ should be different in the\n",
        "two counties.\n",
        "\n",
        "In such a case, you add a *dummy variable*, a third independent\n",
        "variable that is set equal to zero for each data point that is in Santa\n",
        "Clara County (say) and is equal to one for each data point in San Mateo.\n",
        "Then if you run the regression\n",
        "\n",
        "$$\n",
        "\\text{Price of house} = \\beta_0 + \\beta_1 \\times\n",
        "\\text{feet}^2 + \\beta_2\\times\\text{lot size} + \\beta_3\\times\\text{the dummy + chance error}\\,,\n",
        "$$\n",
        "\n",
        "you are effectively estimating the\n",
        "intercept as being $\\beta_0$ for Santa Clara County houses and $\\beta_0 +\\beta_3$ for San Mateo County houses.\n",
        "\n",
        "\n",
        "What if there is a third county, say Alameda, involved? You should then\n",
        "create two dummy variables.  The first (the third variable in the list\n",
        "of independent variables) is $1$ for San Mateo properties and zero for the\n",
        "others.  The second (the fourth variable in the list of independent\n",
        "variables) is $1$ for Alameda and zero for the others.  This will then get\n",
        "you estimates of $\\beta_0$ as the intercept for Santa Clara (both dummies\n",
        "zero), $\\beta_0 + \\beta_3$ for San Mateo, and $\\beta_0 + \\beta_4$ for Alameda.\n",
        "\n",
        "In general, when your data are partitioned according to some\n",
        "characteristic into $k$ classes, you use $k-1$ dummy variables.  Note\n",
        "that you do not use $k$ dummies (that is, in the example, we don't add a\n",
        "third dummy which is $1$ for Santa Clara and zero for the other two).  If\n",
        "you do this, most regression packages will get very unhappy (for mathematical reasons), and will express that unhappiness by\n",
        "some means or other.  (Sophisticated regression packages will say\n",
        "something like \"the regressors are linearly dependent\" and ask you to\n",
        "do something to prevent this.  What you should do in such a case is\n",
        "delete one of the dummy variables.  If this ever happens to you, you probably need to eliminate one or more of your independent variables.)\n",
        "\n",
        "Two points about dummies:\n",
        "\n",
        "1. When you put in a dummy variable (or several),\n",
        "you are effectively allowing the intercept to vary depending on the\n",
        "group the data point belongs to, but you are insisting on the same\n",
        "slope/coefficient for other independent variables, and you are insisting\n",
        "on a pooled estimate for the standard deviation of the residuals.  In\n",
        "the context of our example, with a dummy for San Mateo, you allow for\n",
        "different intercepts or average prices for houses in San Mateo and Santa\n",
        "Clara, but you are still requiring that the marginal value of an extra\n",
        "square foot of house, $\\beta_1$, is the same in the two counties.  If you\n",
        "want to allow for different slopes on square footage in the two\n",
        "counties, but insist on equal slopes/coefficients for lot size and/or\n",
        "pooled estimates for the standard deviations of the residuals, you\n",
        "should use interaction terms, as discussed below.  If you want to allow\n",
        "for completely different regression lines, one for Santa Clara and\n",
        "another for San Mateo, you should simply run two separate regressions.\n",
        "\n",
        "2. Suppose we have houses in Santa Clara and in San\n",
        "Mateo, and houses in incorporated and unincorporated parts of each\n",
        "county.  That is, we have four groups in our data: incorporated Santa\n",
        "Clara, unincorporated Santa Clara, incorporated San Mateo, and\n",
        "unincorporated San Mateo.  If you use three dummies (the first: 1 for\n",
        "incorporated S.C., 0 for the other three categories; the second: 1 for\n",
        "unincorporated S.C., 0 for others; the third: 1 for incorporated S.M., 0\n",
        "for others), you will be allowing for a separate intercept value for\n",
        "each of the four groups.  An alternative *that is not equivalent* is\n",
        "to have two dummies: the first being 1 for San Mateo and 0 for Santa\n",
        "Clara; the second being 1 for unincorporated, 0 for incorporated.  This\n",
        "gives you four different intercept terms, but it forces the difference\n",
        "between incorporated and unincorporated S.C. to be the same as the\n",
        "difference between incorporated and unincorporated S.M.  There may be\n",
        "reasons to force this \"same difference\" property, in which case you\n",
        "would want to use the two-dummy approach.  But if there is no reason to\n",
        "force this, you should use the three-dummy technique.\n",
        "\n",
        "\n",
        "### 5.2 Interaction effects\n",
        "\n",
        "As we pointed out in the introduction of this note, nonlinear\n",
        "transformations of the independent variables allow us to extend the\n",
        "linear model to a more general model of the form\n",
        "\n",
        "$$\n",
        "Y=\\beta_0+f_1(X_1)+\\ldots+f_k(X_k)\n",
        "$$\n",
        "\n",
        "But the model is still restricted\n",
        "in an important way: the effects of the $X_k$'s on $Y$ are *additive*.  This means, for instance, that the effect of $X_1$ on $Y$\n",
        "does not depend on whether $X_2$ is high or low. In many applications\n",
        "however, we might be inclined to suppose that one or more of the independent\n",
        "variables *interact*.\n",
        "\n",
        "To take an example, empirical research has shown that a manufacturing\n",
        "firm, by putting in place so-called lean-production or Kanban-style\n",
        "manufacturing systems can improve its unit costs (after a while).\n",
        "Empirical research has also shown that manufacturing firms can improve\n",
        "unit costs by an array of policies designed to increase worker\n",
        "commitment to the firm, such as employment guarantees, job enrichment\n",
        "and substantial cross-training. What is perhaps more interesting is that\n",
        "the two arrays of policies interact positively: If putting in place a\n",
        "lean-production system improves unit costs by 25% after a year, and\n",
        "high-commitment HRM (human resource management) policies improve unit\n",
        "costs by 15%, the a combination of the two gives improvements of more\n",
        "than the sum of the two -- improvements of 50% might be seen.\n",
        "\n",
        "**Remark:** These are *not* right numbers; they are used only for illustrative\n",
        "purposes. You may discuss this in other courses (e.g., HRM); watch for the article by MacDuffie and Kraftchik.\n",
        "\n",
        "This is an example of two complementary effects, where the whole is\n",
        "greater than the sum of its parts. There are also well-known examples of\n",
        "supplementary effects, e.g. increasing worker productivity by\n",
        "intrusive monitoring \"gets in the way\"\" of increases in worker\n",
        "productivity by worker empowerment (and vice versa).\n",
        "\n",
        "Because a linear regression suppose additive effects, it does not seem\n",
        "to be a tool that can be used to study interaction effects. But there\n",
        "are various tricks that can be employed, which allow for interaction\n",
        "effects to be studied.\n",
        "\n",
        "#### Creating a new independent variable\n",
        "\n",
        "One trick that sometimes works when you suspect that two variables have\n",
        "an interaction effect is to create a third independent variable which is\n",
        "the product of the two. That is if we have three independent variables\n",
        "and we think variables $X_1$ and $X_3$ will interact, we look at the\n",
        "regression\n",
        "\n",
        "$$\n",
        "Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2\n",
        "+ \\beta_3 X_3 + \\gamma X_1 \\times X_3 + \\text{chance error}\n",
        "$$\n",
        "\n",
        "In practice, we do this by taking a data-sheet with columns\n",
        "for $Y, X_1, X_2$ and $X_3$ and creating a fifth column with\n",
        "$X_1 \\times X_3$. Then when we regress, we specify the fifth column as an extra independent variable. Some software packages (such as R), allowe easier ways of doing this. You would just need to write down the interaction term in the formula that is provided to `slf.ols` command. We will show you this in class.\n",
        "\n",
        "When we do this, if the coefficient estimating $\\gamma$ comes out\n",
        "positive (and significant), we are documenting a positive interaction\n",
        "effect; raising $X_1$ increases the (positive) impact of a simultaneous\n",
        "rise in $X_3$ and vice versa. If the coefficient estimating $\\gamma$\n",
        "comes out negative, we  have a negative interaction between $X_1$ and\n",
        "$X_3$, at least insofar the impact on $Y$ is concerned.\n",
        "\n",
        "Of course the functional form $X_1 \\times X_3$ is very special.  There\n",
        "are all sorts of functional forms for an interaction between $X_1$ and\n",
        "$X_3$ and there is no reason a priori to think that a simple product is\n",
        "best.  But the product form gets used a lot, for the same reason one\n",
        "adds the square of a column as an extra independent variable; it is\n",
        "simple and convenient.  It would be nice to have some *a priori*\n",
        "guidance on what sort of functional form should be used for the\n",
        "interaction, and in some cases you will have that a priori guidance.\n",
        "But when you don't, a simple product is better than no interaction terms\n",
        "at all if you think it likely that there is some interaction.\n",
        "\n",
        "To illustrate the use of a product term, we come back to the example of\n",
        "the previous paragraph on house prices in San Mateo and Santa Clara.\n",
        "Let's say that we are willing to assume that both average house prices\n",
        "and the effect of square footage on the price of a house are different\n",
        "in the two counties (but the effect of lot size and the standard\n",
        "deviation of the residuals are the same).  We will then create an\n",
        "additional variable equal to the product of the dummy variable and of\n",
        "the square footage variable and run the following regression\n",
        "\n",
        "$$\n",
        "\\text{Price of house} = \\beta_0 + \\beta_1 \\times\n",
        "\\text{feet}^2 + \\beta_2\\times\\text{lot size} + \\gamma\\text{ dummy}\\times\\text{feet}^2 +\\text{chance error}\\,.\n",
        "$$\n",
        "\n",
        "This regression allows the effect of square footage to be\n",
        "different in the two counties.  To see this consider first the effect of\n",
        "square footage for a Santa Clara house.  The dummy is zero in Santa\n",
        "Clara as well as the product term.  Therefore the effect of an\n",
        "additional square foot on the price of the house is $\\beta_1$.  For a San\n",
        "Mateo house things are different however because the product term is\n",
        "equal to $\\text{feet}^2$ (the dummy is one in San Mateo.) Therefore the effect\n",
        "of an additional square foot is $\\beta_1+\\gamma$.\n",
        "\n",
        "#### Partitioning the data and running separate regressions}\n",
        "\n",
        "A second technique is especially useful when one of the\n",
        "potentially interacting variables is a 0/1 dummy variable.  Then you can\n",
        "simply partition your data set into two pieces -- those where the dummy\n",
        "has the value zero and those where the dummy has the value one -- and\n",
        "run two separate regressions.  (This will require that you have a\n",
        "substantial number of observations in each of the two pools.) If you\n",
        "think there is an interaction between you dummy variable and some other\n",
        "variable, this will turn up if the regression coefficients on the second\n",
        "variable come out (significantly) different in the two separated\n",
        "regressions.\n",
        "\n",
        "Coming back to the example on house prices, if we want to allow for\n",
        "completely different regression lines for San Mateo and Santa Clara\n",
        "(i.e. different constant terms, effects of footage and lot size and\n",
        "standard deviations of the residuals) we just run two separate\n",
        "regressions.\n",
        "\n",
        "Which technique should you choose? (Note well that to have a choice, one\n",
        "of the interacting variables must be a dummy variable or, more\n",
        "generally, must take a very small number of different values.) The\n",
        "choice depends pretty much on what you are willing to assume about the\n",
        "regression coefficients.  If you believe that there a significant chance\n",
        "that all coefficients should be different then you should run separate\n",
        "regressions.  If, in contrast, you believe that it is sensible to impose\n",
        "some constraints on the coefficients (and on the standard deviation of\n",
        "the residuals) you should simply introduce interaction terms.\n",
        "\n",
        "### 5.3 Building a regression model\n",
        "\n",
        "So far, most of our discussion on regression focused on how to analyze a\n",
        "*given* regression model.  However a more difficult question sometimes is\n",
        "how to *build* a regression model.  It may well happen that you are\n",
        "faced with a long list of variables and want to select only a few to\n",
        "include in the model.  Even though your initial set of variables may be\n",
        "limited, you are certainly able to create a much larger set of variables\n",
        "after reading the first part of this note.\n",
        "\n",
        "Before you build a regression model you should try to understand as well\n",
        "as you can the problem that you are studying.  You should determine *on a priori grounds* the most important factors that may explain the\n",
        "dependent variable and then find the appropriate independent variables\n",
        "to include.  This step may seem just natural to you, but experience with\n",
        "regression projects shows that it is often neglected.\n",
        "\n",
        "Ideally, after this stage you have singled out a small number of\n",
        "independent variables (compared to the amount of data that you have).\n",
        "You then use regression to estimate the coefficients of these\n",
        "independent variables.\n",
        "\n",
        "Things may not work so well if you are studying a fairly complex problem\n",
        "and it is difficult to single out a few important independent variables\n",
        "(an example will soon follow).  In addition, even if you decide on a\n",
        "small number of independent variables you may be uncertain of the exact\n",
        "form of the relationship between them and the dependent variable.  For\n",
        "instance you may believe that there is an important interaction between\n",
        "two independent variables or that an independent variable has a\n",
        "nonlinear effect on the dependent variable.  Your problems will\n",
        "naturally be greater if you have few data.\n",
        "\n",
        "## 6. The problem of overfitting\n",
        "\n",
        "So what should you do if you find yourself in this unhappy situation? Let's\n",
        "first illustrate by an analogy what you should *not* do.\n",
        "\n",
        "Suppose that a particular very virulent but very rare form of cancer has\n",
        "been detected.  This form of cancer is so rare that there are only seven\n",
        "cases reported in medical annals.  Notwithstanding its rarity, a\n",
        "researcher studies this form of cancer, to see whether some pre-existing\n",
        "condition (of the patient) might be found that indicates susceptibility\n",
        "to this form of cancer.\n",
        "\n",
        "Medical research has not yet singled out a few important factors that\n",
        "cause cancer (and especially this new form of cancer).  Therefore our\n",
        "researcher studies many aspects of the medical and personal histories of\n",
        "the seven victims and makes an exciting discovery.  All seven had large\n",
        "ear lobes, five of the seven had blue eyes, and of those five, four were\n",
        "audited by the IRS within three years of contracting the condition.\n",
        "Thus the researcher reports that blue-eyed individuals with large ear\n",
        "lobes who have had recent problems with the IRS should seek medical\n",
        "counsel --- they are at great risk!\n",
        "\n",
        "Presumably you see through this story.  If you look at any seven people,\n",
        "you are bound to find some set of common characteristics that they\n",
        "share, and you are sure to do so if your standards of common stretch to\n",
        "five out of the seven.  They will have something or things in common.\n",
        "But this is a matter of random happenstance --- you wouldn't want to\n",
        "predict that an eighth person with this set of characteristics is any\n",
        "more at risk for contracting the condition than is an eighth person\n",
        "without the common characteristics, unless you had some physiological\n",
        "basis for suspecting that the characteristics are carcinogenic.  Blue\n",
        "eyes, large ear lobes, and IRS attention, even combined, are probably\n",
        "not carcinogenic.\n",
        "\n",
        "The analog of the researcher's procedure in our context (building a\n",
        "regression model) consists in \"trying out\" many independent variables\n",
        "and keeping only the ones that work.  There are many ways to do this.\n",
        "The most direct way is to literally try out a large number of possible\n",
        "regressions and choose the combination of independent variables that\n",
        "produces the highest adjusted R-squared.  But there are also indirect\n",
        "ways to do this.  For instance one may examine the data before choosing\n",
        "to include a nonlinear term or an interaction term and include the term\n",
        "only if the data suggests that the term should be present.\n",
        "\n",
        "From the point of view of the statistical properties of regression, this\n",
        "is bad procedure because it invalidates all the confidence intervals and\n",
        "hypothesis tests that the regression package provides.  All those tests\n",
        "and confidence intervals assume that you have with a fixed set of\n",
        "independent variables and you run the regression once.  If instead you\n",
        "use the data to try out all the independent variables and keep only the\n",
        "ones that work, the regression package will (falsely) attribute a great\n",
        "deal of significance in your results.\n",
        "\n",
        "To come back to\n",
        "our analogy, if our medical researcher attempted to explain\n",
        "susceptibility to the new form of cancer by large ear lobes, blue eyes\n",
        "and IRS attention *only* he would get an impressive adjusted\n",
        "R-squared.\n",
        "\n",
        "### 6.1 Adding versus trying out variables\n",
        "\n",
        "The problem we are trying to avoid is not in adding independent variables to\n",
        "the model but in trying them out and deleting them if they do not\n",
        "improve the fit to the data.\n",
        "\n",
        "When you add independent variables you will always fit better the\n",
        "dependent variable and increase your R-squared.  At the extreme, if you\n",
        "have 100 observations in the data set and 99 independent variables (plus\n",
        "a constant term), you will necessarily explain all the variation in the\n",
        "dependent variable and your R-squared will be 1.\n",
        "\n",
        "**Remark:** This is a\n",
        "mathematical fact and requires all 99 variables to be linearly\n",
        "independent and independent of the constant vector, something which is\n",
        "entirely usual in these situations.\n",
        "\n",
        "Of course, this better \"fit\"\" is to the particular data sample you have.\n",
        "You won't really be explaining the general relationship between your\n",
        "independent and dependent variables; you will be finding an explanation\n",
        "for the specific relationship in your sample.  (This can be seen, for\n",
        "example, by the fact that the regression coefficients will be highly\n",
        "sensitive to the specific data sample.  Change one value of the\n",
        "dependent variable by 1 or 2%, and your coefficients are likely to jump\n",
        "wildly to very different values.)\n",
        "\n",
        "However a regression package will not give you misleading results.  It\n",
        "will penalize you for adding variables by reducing your degrees of\n",
        "freedom.  While adding another independent variable will almost\n",
        "inevitably raise your unadjusted R-squared (and can never lower it),\n",
        "unless the new variable adds significantly to your ability to predict\n",
        "the dependent variable, adjusted R-squared will fall.\n",
        "\n",
        "You also are penalized for adding independent variables in terms of\n",
        "confidence intervals and hypothesis testing about the coefficients.\n",
        "For one thing, adding an independent variable reduces by one your\n",
        "degrees of freedom, which widens confidence intervals and lowers\n",
        "just-significant probabilities.  For a second (and more subtle) thing,\n",
        "adding an independent variable will tend to increase the standard\n",
        "errors of your coefficients.\n",
        "\n",
        "**Remark:** It does this because it will\n",
        "tend to make the matrix of regressors more nearly singular, in\n",
        "something like the fashion that highly correlated regressors increases\n",
        "standard errors.  But this is hard to explain unless you know some\n",
        "matrix algebra.\n",
        "\n",
        "The regression package will give you the wrong statistics when you start\n",
        "deleting variables. It will falsely assume that you did not try out many\n",
        "variables and that the good fit that you got was not due to luck. Since\n",
        "you will not be penalized in terms of degrees of freedom, you will get a\n",
        "high adjusted R-squared and tight confidence intervals.\n",
        "\n",
        "#### What to do?\n",
        "\n",
        "So let's say that you are stuck with few data and you believe that a\n",
        "large number of independent variables (including dummies, nonlinear\n",
        "transformations and interaction terms) would help in explaining the\n",
        "dependent variable. How should you use your regression package?\n",
        "\n",
        "First of all, in such a situation you should not expect to learn much\n",
        "about the relationship between the dependent and the independent\n",
        "variables even if you follow very sophisticated statistical procedures.\n",
        "But at least here is a correct way to use your regression package.\n",
        "\n",
        "You should randomly split your sample in two halves. You will use the\n",
        "first half to decide which variables to include and build your model.\n",
        "After building your model you will estimate/test it on the second half.\n",
        "*If* you build a model with explanatory power based on the first\n",
        "subset of your data, it should have a high adjusted R-squared when\n",
        "applied to the second subset (almost as high on average as on the subset\n",
        "of data from which it was designed).  If the model you build works well\n",
        "for the set of data from which it was designed but works noticeably more\n",
        "poorly for independent copies of data, then you probably have a model\n",
        "that simply reflects the peculiarities of the data set used to build it.\n",
        "\n",
        "You should be careful in the first stage of model-building and not\n",
        "follow the mechanical procedure of maximizing adjusted R-squared.  Even\n",
        "if you don't know the form of the relationship between dependent and\n",
        "independent variables, you will probably have some sense of what that\n",
        "relationship might be and you should guard against the inclusion of\n",
        "independent variables that do a good job of \"explanation\" (in the\n",
        "statistical sense) but otherwise make no sense on the face of things."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwxw6JyC2YwH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}